{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5347371,"sourceType":"datasetVersion","datasetId":3027350}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nfrom tqdm import tqdm\nimport shutil\n#---------------------------------------\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n#---------------------------------------\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\nfrom sklearn.model_selection import KFold\n#---------------------------------------\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-21T15:29:47.838468Z","iopub.execute_input":"2024-11-21T15:29:47.838804Z","iopub.status.idle":"2024-11-21T15:30:00.905361Z","shell.execute_reply.started":"2024-11-21T15:29:47.838772Z","shell.execute_reply":"2024-11-21T15:30:00.904441Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def move_files(file_paths, labels, train_dirs):\n    with tqdm(total=len(file_paths), desc=\"Moving Files\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\") as pbar:\n        for file_path, label in zip(file_paths, labels):\n            if label == 0:  # bottle\n                target_dir = train_dirs[0]\n            elif label == 1:  # canister\n                target_dir = train_dirs[1]\n            elif label == 2:  # cans\n                target_dir = train_dirs[2]\n            elif label == 3:  # cardboard\n                target_dir = train_dirs[3]\n            elif label == 4:  # detergent\n                target_dir = train_dirs[4]\n            \n            # Copy the file to the target directory\n            shutil.copy(file_path, target_dir)\n            pbar.update(1)  # Update progress bar by 1 step\n\n\n\ndef data_prep(input_dir, output_dir,i):\n\n    # Define output directories for each class in the train set\n    train_dir = os.path.join(output_dir, i)\n    train_bottle_dir = os.path.join(train_dir, 'bottle')\n    train_canister_dir = os.path.join(train_dir, 'canister')\n    train_cans_dir = os.path.join(train_dir, 'cans')\n    train_cardboard_dir = os.path.join(train_dir, 'cardboard')\n    train_detergent_dir = os.path.join(train_dir, 'detergent')\n\n    # Create the directories if they don't exist\n    os.makedirs(train_bottle_dir, exist_ok=True)\n    os.makedirs(train_canister_dir, exist_ok=True)\n    os.makedirs(train_cans_dir, exist_ok=True)\n    os.makedirs(train_cardboard_dir, exist_ok=True)\n    os.makedirs(train_detergent_dir, exist_ok=True)\n\n    # Collect images from subdirectories under the bottle class\n    bottle_dir = os.path.join(input_dir, 'bottle')\n    bottle_images = []\n    for subdir in os.listdir(bottle_dir):\n        subdir_path = os.path.join(bottle_dir, subdir)\n        if os.path.isdir(subdir_path):  # Ensure it's a directory\n            bottle_images.extend([os.path.join(subdir_path, img) for img in os.listdir(subdir_path)])\n\n    # Repeat for other categories\n    canister_dir = os.path.join(input_dir, 'canister/canister')\n    canister_images = [os.path.join(canister_dir, img) for img in os.listdir(canister_dir) if os.path.isfile(os.path.join(canister_dir, img))]\n\n    cans_dir = os.path.join(input_dir, 'cans/cans')\n    cans_images = [os.path.join(cans_dir, img) for img in os.listdir(cans_dir) if os.path.isfile(os.path.join(cans_dir, img))]\n\n    cardboard_dir = os.path.join(input_dir, 'cardboard')\n    cardboard_images = []\n    for subdir in os.listdir(cardboard_dir):\n        subdir_path = os.path.join(cardboard_dir, subdir)\n        if os.path.isdir(subdir_path):  # Ensure it's a directory\n            cardboard_images.extend([os.path.join(subdir_path, img) for img in os.listdir(subdir_path)])\n\n    detergent_dir = os.path.join(input_dir, 'detergent')\n    detergent_images = []\n    for subdir in os.listdir(detergent_dir):\n        subdir_path = os.path.join(detergent_dir, subdir)\n        if os.path.isdir(subdir_path):  # Ensure it's a directory\n            detergent_images.extend([os.path.join(subdir_path, img) for img in os.listdir(subdir_path)])\n\n    # Combine the data and create labels\n    images = bottle_images + canister_images + cans_images + cardboard_images + detergent_images\n    labels = [0] * len(bottle_images) + [1] * len(canister_images) + [2] * len(cans_images) + [3] * len(cardboard_images) + [4] * len(detergent_images)\n    # Define train directories for each class\n    train_dirs = [train_bottle_dir, train_canister_dir, train_cans_dir, train_cardboard_dir, train_detergent_dir]\n    # Move training data\n    print(f\"Moving {i} data...\")\n    move_files(images, labels, train_dirs)\n\n    print(f\"{i} data successfully moved to train directories.\")\n    \n\n\n# Function to move files to train folder with progress bar\ndef move_files(file_paths, labels, train_dirs):\n    with tqdm(total=len(file_paths), desc=\"Moving Files\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\") as pbar:\n        for file_path, label in zip(file_paths, labels):\n            if label == 0:  # bottle\n                target_dir = train_dirs[0]\n            elif label == 1:  # canister\n                target_dir = train_dirs[1]\n            elif label == 2:  # cans\n                target_dir = train_dirs[2]\n            elif label == 3:  # cardboard\n                target_dir = train_dirs[3]\n            elif label == 4:  # detergent\n                target_dir = train_dirs[4]\n            \n            # Copy the file to the target directory\n            shutil.copy(file_path, target_dir)\n            pbar.update(1)  # Update progress bar by 1 step","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:30:00.906936Z","iopub.execute_input":"2024-11-21T15:30:00.907447Z","iopub.status.idle":"2024-11-21T15:30:00.923037Z","shell.execute_reply.started":"2024-11-21T15:30:00.907418Z","shell.execute_reply":"2024-11-21T15:30:00.922140Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data_prep(\"/kaggle/input/warp-waste-recycling-plant-dataset/Warp-C/train_crops\",\"/kaggle/working/\",\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:30:00.924065Z","iopub.execute_input":"2024-11-21T15:30:00.924356Z","iopub.status.idle":"2024-11-21T15:30:50.071036Z","shell.execute_reply.started":"2024-11-21T15:30:00.924331Z","shell.execute_reply":"2024-11-21T15:30:50.070181Z"}},"outputs":[{"name":"stdout","text":"Moving train data...\n","output_type":"stream"},{"name":"stderr","text":"Moving Files: 100%|██████████| 8823/8823","output_type":"stream"},{"name":"stdout","text":"train data successfully moved to train directories.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data_prep(\"/kaggle/input/warp-waste-recycling-plant-dataset/Warp-C/test_crops\",\"/kaggle/working/\",\"test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:30:50.073613Z","iopub.execute_input":"2024-11-21T15:30:50.074317Z","iopub.status.idle":"2024-11-21T15:30:57.703549Z","shell.execute_reply.started":"2024-11-21T15:30:50.074271Z","shell.execute_reply":"2024-11-21T15:30:57.702680Z"}},"outputs":[{"name":"stdout","text":"Moving test data...\n","output_type":"stream"},{"name":"stderr","text":"Moving Files: 100%|██████████| 1551/1551","output_type":"stream"},{"name":"stdout","text":"test data successfully moved to train directories.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Create directories for the dataset\n!mkdir -p /kaggle/working/train/images\n!mkdir -p /kaggle/working/train/labels\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:30:57.704799Z","iopub.execute_input":"2024-11-21T15:30:57.705157Z","iopub.status.idle":"2024-11-21T15:30:59.792913Z","shell.execute_reply.started":"2024-11-21T15:30:57.705110Z","shell.execute_reply":"2024-11-21T15:30:59.791851Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport shutil\nfrom tqdm import tqdm\n\n# Define source and destination paths\nsource_images = '/kaggle/input/warp-waste-recycling-plant-dataset/Warp-D/train/images/'\nsource_labels = '/kaggle/input/warp-waste-recycling-plant-dataset/Warp-D/train/labels/'\nsource_classes = '/kaggle/input/warp-waste-recycling-plant-dataset/Warp-D/classes.txt'\n\ndest_images = '/kaggle/working/train/images/'\ndest_labels = '/kaggle/working/train/labels/'\ndest_classes = '/kaggle/working/classes.txt'\n\n# Create destination directories if they don't exist\nos.makedirs(dest_images, exist_ok=True)\nos.makedirs(dest_labels, exist_ok=True)\n\n# Copy images to the images directory\nimage_files = os.listdir(source_images)\nwith tqdm(total=len(image_files), desc=\"Copying Images\", unit=\"file\") as pbar:\n    for filename in image_files:\n        shutil.copy2(os.path.join(source_images, filename), os.path.join(dest_images, filename))\n        pbar.update(1)  # Update the progress bar\n\n# Copy labels to the labels directory\nlabel_files = os.listdir(source_labels)\nwith tqdm(total=len(label_files), desc=\"Copying Labels\", unit=\"file\") as pbar:\n    for filename in label_files:\n        shutil.copy2(os.path.join(source_labels, filename), os.path.join(dest_labels, filename))\n        pbar.update(1)  # Update the progress bar\n\n# Copy classes.txt to the working directory\nshutil.copy2(source_classes, dest_classes)\n\n# Print confirmation\nprint(\"Files copied successfully!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:30:59.794789Z","iopub.execute_input":"2024-11-21T15:30:59.795600Z","iopub.status.idle":"2024-11-21T15:31:34.592262Z","shell.execute_reply.started":"2024-11-21T15:30:59.795552Z","shell.execute_reply":"2024-11-21T15:31:34.591266Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Copying Images: 100%|██████████| 2452/2452 [00:22<00:00, 110.22file/s]\nCopying Labels: 100%|██████████| 2452/2452 [00:12<00:00, 198.41file/s]","output_type":"stream"},{"name":"stdout","text":"Files copied successfully!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport shutil\nfrom tqdm import tqdm\n\n# Define source and destination paths\nsource_images = '/kaggle/input/warp-waste-recycling-plant-dataset/Warp-D/test/images'\nsource_labels = '/kaggle/input/warp-waste-recycling-plant-dataset/Warp-D/test/labels'\n\ndest_images = '/kaggle/working/val/images/'\ndest_labels = '/kaggle/working/val/labels/'\n\n# Create destination directories if they don't exist\nos.makedirs(dest_images, exist_ok=True)\nos.makedirs(dest_labels, exist_ok=True)\n\n# Copy images to the images directory\nimage_files = os.listdir(source_images)\nwith tqdm(total=len(image_files), desc=\"Copying Images\", unit=\"file\") as pbar:\n    for filename in image_files:\n        shutil.copy2(os.path.join(source_images, filename), os.path.join(dest_images, filename))\n        pbar.update(1)  # Update the progress bar\n\n# Copy labels to the labels directory\nlabel_files = os.listdir(source_labels)\nwith tqdm(total=len(label_files), desc=\"Copying Labels\", unit=\"file\") as pbar:\n    for filename in label_files:\n        shutil.copy2(os.path.join(source_labels, filename), os.path.join(dest_labels, filename))\n        pbar.update(1)  # Update the progress bar\n\n# Copy classes.txt to the working directory\nshutil.copy2(source_classes, dest_classes)\n\n# Print confirmation\nprint(\"Files copied successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:31:34.593465Z","iopub.execute_input":"2024-11-21T15:31:34.593727Z","iopub.status.idle":"2024-11-21T15:31:40.876304Z","shell.execute_reply.started":"2024-11-21T15:31:34.593701Z","shell.execute_reply":"2024-11-21T15:31:40.875418Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Copying Images: 100%|██████████| 522/522 [00:04<00:00, 123.74file/s]\nCopying Labels: 100%|██████████| 522/522 [00:01<00:00, 269.83file/s]","output_type":"stream"},{"name":"stdout","text":"Files copied successfully!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Read class names from the classes.txt file\nwith open(\"classes.txt\", \"r\") as f:\n    class_names = [line.strip() for line in f.readlines() if line.strip()]  # Avoid empty lines\n\n# Determine the number of classes\nnum_classes = len(class_names)\n\n# Create YAML file content\nyaml_content = f\"\"\"\npath: /kaggle/working/\ntrain: /kaggle/working/train\nval: /kaggle/working/val\n\nnc: {num_classes}\nnames: {class_names}\n\"\"\"\n\n# Write the content to a YAML file\nwith open(\"dataset.yaml\", \"w\") as file:\n    file.write(yaml_content)\n\n# Print the YAML content for verification\nprint(\"Generated YAML file content:\")\nprint(yaml_content)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:31:40.877447Z","iopub.execute_input":"2024-11-21T15:31:40.877715Z","iopub.status.idle":"2024-11-21T15:31:40.884491Z","shell.execute_reply.started":"2024-11-21T15:31:40.877689Z","shell.execute_reply":"2024-11-21T15:31:40.883613Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Generated YAML file content:\n\npath: /kaggle/working/\ntrain: /kaggle/working/train\nval: /kaggle/working/val\n\nnc: 28\nnames: ['bottle-blue', 'bottle-green', 'bottle-dark', 'bottle-milk', 'bottle-transp', 'bottle-multicolor', 'bottle-yogurt', 'bottle-oil', 'cans', 'juice-cardboard', 'milk-cardboard', 'detergent-color', 'detergent-transparent', 'detergent-box', 'canister', 'bottle-blue-full', 'bottle-transp-full', 'bottle-dark-full', 'bottle-green-full', 'bottle-multicolorv-full', 'bottle-milk-full', 'bottle-oil-full', 'detergent-white', 'bottle-blue5l', 'bottle-blue5l-full', 'glass-transp', 'glass-dark', 'glass-green']\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install ultralytics\n\nfrom ultralytics import YOLO\n\n# Load the pre-trained YOLOv8 model\nmodel = YOLO(\"yolov8n.pt\")\n\n# Start training\nmodel.train(\n    data=\"/kaggle/working/dataset.yaml\",  # Path to your YAML file\n    epochs=10,\n    batch=16,\n    imgsz=640,\n    name=\"custom_yolo_model\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:31:40.885631Z","iopub.execute_input":"2024-11-21T15:31:40.885890Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.35-py3-none-any.whl.metadata (35 kB)\nRequirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (10.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.14.1)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.4.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.19.0)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.3.35-py3-none-any.whl (887 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.35 ultralytics-thop-2.0.12\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.25M/6.25M [00:00<00:00, 269MB/s]","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.35 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/dataset.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=custom_yolo_model, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/custom_yolo_model\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 31.1MB/s]\n2024-11-21 15:31:59,292\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-11-21 15:31:59,783\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=28\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    756772  ultralytics.nn.modules.head.Detect           [28, [64, 128, 256]]          \nModel summary: 225 layers, 3,016,308 parameters, 3,016,292 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/custom_yolo_model', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5.35M/5.35M [00:00<00:00, 312MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/train/bottle... 2452 images, 5131 backgrounds, 0 corrupt: 100%|██████████| 7583/7583 [00:04<00:00, 1644.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/train/bottle.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/val/labels... 522 images, 0 backgrounds, 0 corrupt: 100%|██████████| 522/522 [00:00<00:00, 840.88it/s] ","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/val/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/custom_yolo_model/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000313, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/custom_yolo_model\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/20       2.4G      1.516       4.83      1.325         37        640: 100%|██████████| 474/474 [01:31<00:00,  5.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:04<00:00,  4.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        522       1551      0.236      0.166     0.0651     0.0479\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/20      2.36G      1.372      3.935      1.255         42        640:  37%|███▋      | 175/474 [00:32<00:55,  5.43it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import glob \nfrom PIL import Image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images=glob.glob('/kaggle/working/val/images/*')\nresults=model([images[0]],stream=False)\nres=results[0].plot()\nImage.fromarray(res)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}